% Encoding: UTF-8

@Article{Siddiqui2018,
    author  = {Siddiqui, Shoaib and Malik, Muhammad Imran and Agne, Stefan and Dengel, Andreas and Ahmed, Sheraz},
    title   = {DeCNT: Deep Deformable CNN for Table Detection},
    doi     = {10.1109/ACCESS.2018.2880211},
    pages   = {1-1},
    volume  = {PP},
    journal = {IEEE Access},
    month   = {11},
    year    = {2018},
}

@InProceedings{Gatos2005,
    author = {Gatos, Basilios and Danatsas, Dimitrios and Pratikakis, Ioannis and Perantonis, Stavros},
    title  = {Automatic Table Detection in Document Images},
    doi    = {10.1007/11551188_67},
    pages  = {609-618},
    volume = {3686},
    month  = {08},
    year   = {2005},
}

@InProceedings{Li2006,
    author    = {Li, Juanzi and Tang, Jie and Song, Qiang and Xu, Peng},
    booktitle = {Frontiers of WWW Research and Development - APWeb 2006},
    title     = {Table Detection from Plain Text Using Machine Learning and Document Structure},
    editor    = {Zhou, Xiaofang and Li, Jianzhong and Shen, Heng Tao and Kitsuregawa, Masaru and Zhang, Yanchun},
    isbn      = {978-3-540-32437-9},
    pages     = {818--823},
    publisher = {Springer Berlin Heidelberg},
    abstract  = {Addressed in this paper is the issue of table extraction from plain text. Table is one of the commonest modes for presenting information. Table extraction has applications in information retrieval, knowledge acquisition, and text mining. Automatic information extraction from table is a challenge. Existing methods was mainly focusing on table extraction from web pages (formatted table extraction). So far the problem of table extraction on plain text, to the best of our knowledge, has not received sufficient attention. In this paper, unformatted table extraction is formalized as unformatted table block detection and unformatted table row identification. We concentrate particularly on the table extraction from Chinese documents. We propose to conduct the task of table extraction by combining machine learning methods and document structure. We first view the task as classification and propose a statistical approach to deal with it based on Na{\"i}ve Bayes. We define features in the classification model. Next, we use document structure to improve the detection performance. Experimental results indicate that the proposed methods can significantly outperform the baseline methods for unformatted table extraction.},
    address   = {Berlin, Heidelberg},
    year      = {2006},
}

@Unknown{Qasim2019,
    author = {Qasim, Shah Rukh and Mahmood, Hassan and Shafait, Faisal},
    month  = {07},
    title  = {Rethinking Table Recognition using Graph Neural Networks},
    year   = {2019},
}

@InProceedings{Oliveira2017,
  author    = {D. A. B. {Oliveira} and M. P. {Viana}},
  booktitle = {2017 IEEE International Conference on Computer Vision Workshops (ICCVW)},
  date      = {2017-10-22},
  title     = {Fast CNN-Based Document Layout Analysis},
  doi       = {10.1109/ICCVW.2017.142},
  pages     = {1173-1180},
  issn      = {2473-9944},
  keywords  = {document image processing;feature extraction;feedforward neural nets;image retrieval;pattern clustering;text analysis;information extraction;mobile devices;content boxes;structured data;images understanding;specific-domain knowledge database creation;cognitive computing;automatic document layout analysis;fast CNN;compact data usage;bi-dimensional documents images;dimension analysis;table blocks;text;one-dimensional pattern;one-dimensional approach;cloud-based services;Databases;Computer architecture;Training;Layout;Text analysis;Image segmentation;Two dimensional displays},
  month     = {Oct},
  year      = {2017},
}

@Article{Nazemi2016,
    author       = {Nazemi, Azadeh and Murray, Iain and Fernaando, Chandrika and McMeekin, David A.},
    date         = {2016},
    journaltitle = {World Journal of Education},
    title        = {Converting Optically Scanned Regular or Irregular Tables to a Standardised Markup Format to Be Accessible to Vision-Impaired},
    issn         = {1925-0746},
    number       = {5},
    pages        = {p9-19},
    url          = {https://eric.ed.gov/?id=EJ1158245},
    urldate      = {2019},
    volume       = {6},
}

@InProceedings{Schreiber2017,
  author    = {S. {Schreiber} and S. {Agne} and I. {Wolf} and A. {Dengel} and S. {Ahmed}},
  booktitle = {2017 14th IAPR International Conference on Document Analysis and Recognition (ICDAR)},
  date      = {2017-11-09},
  title     = {DeepDeSRT: Deep Learning for Detection and Structure Recognition of Tables in Document Images},
  doi       = {10.1109/ICDAR.2017.192},
  pages     = {1162-1167},
  volume    = {01},
  issn      = {2379-2140},
  keywords  = {document image processing;feature extraction;image classification;image segmentation;learning (artificial intelligence);DeepDeSRT;deep learning;document images;end-to-end system;table understanding;table structure recognition;structure recognition methods;scanned documents;rule-based methods;table detection;ICDAR 2013 table competition dataset;Portable document format;Image recognition;Machine learning;Training;Metadata;Task analysis;Feature extraction},
  month     = {Nov},
  year      = {2017},
}

@Online{ApothekersNetwerk2013,
  author   = {Vlaams Apothekersnetwerk},
  date     = {2013-07-27},
  title    = {Standpunt medicatieschema},
  url      = {https://vlaamsapothekersnetwerk.be/index.php/informatie/nieuws/8-berichten-van/54-van-standpunt-medicatieschema},
  abstract = {Naar aanleiding van het Actieplan 2013-2015 voor de verankering van de apotheker in de 1ste lijn, waarin het medicatieschema één van de 5 pijlers is, heeft het Vlaams Apothekers Netwerk in overleg met APB standpunt ingenomen over het belang van het medicatieschema in de apotheek en in de eerstelijnsgezondheidszorg.},
}

@Comment{jabref-meta: databaseType:biblatex;}
