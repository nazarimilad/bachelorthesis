% Encoding: UTF-8

@Report{FederaleOverheidsdienstEconomie,
  author      = {Federale Overheidsdienst Economie, K.M.O., Middenstand en Energie},
  date        = {2019},
  institution = {Federale Overheidsdienst Economie, K.M.O., Middenstand en Energie},
  title       = {Barometer van de informatiemaatschappij (2019)},
  type        = {resreport},
}

@Article{Zanibbi2003,
  author   = {R. Zanibbi and D. Blostein and J. Cordy},
  date     = {2003-10-24},
  title    = {A Survey of Table Recognition: Models, Observations, Transformations, and Inferences},
  abstract = {Table characteristics vary widely. Consequently, a great variety of computational approaches
have been applied to table recognition. In this survey, the table recognition literature is
presented as an interaction of table models, observations, transformations and inferences. A
table model defines the physical and logical structure of tables; the model is used to detect
tables, and to analyze and decompose the detected tables. Observations perform feature
measurements and data lookup, transformations alter or restructure data, and inferences
generate and test hypotheses. This presentation clarifies the decisions that are made by a table
recognizer, and the assumptions and inferencing techniques that underlie these decisions.},
}

@Thesis{Long2010,
  author      = {Vanessa Long},
  date        = {2010-05-23},
  institution = {Department of Computing, Macquarie University},
  title       = {An Agent-Based ApproachtoTable Recognition and Interpretation},
  type        = {phdthesis},
}

@Thesis{Wang1996,
  author      = {Xinxin Wang},
  date        = {1996},
  institution = {University of Waterloo},
  title       = {Tabular Abstraction, Editing, and Formatting},
  type        = {phdthesis},
  abstract    = {This dissertation investigates the composition of high-quality tables with the use of electronic tools. A generic model is designed to support the different stages of tabular composition, including the editing of logical structure, the specification of layout
structure, and the formatting of concrete tables. The model separates table's logical
structure from its layout structure, which consists of tabular topology and typographic
style. The notion of an abstract table, which describes the logical relationships among
tabular items, is formally defined and a set of logical operations is proposed to manipulate tables based on these logical relationships. An abstract table can be visualized
through a layout structure specified by a set of topological rules, which determine the
relative placement of tabular items in two dimensions, and a set of style rules, which
determine the final appearance of different items. The absolute placement of a concrete
table can be automatically generated by applying a layout specification to an abstract
table. An NP-complete problem arises in the formatting process that uses automatic
line breaking and determines the physical dimension of a table to satisfy user-specified
size constraints. An algorithm has been designed to solve the formatting problem in
polynomial time for typical tables. Based on the tabular model, a prototype tabular
composition system has been implemented in a UNIX, X Windows environment. This
prototype provides an interactive interface to edit the logical structure, the topology and
the styles of tables. It allows us to manipulate tables based on the logical relationships
of tabular items, regardless of where the items are placed in the layout structure, and
is capable of presenting a table in different topologies and styles so that we can select a
high-quality layout structure.},
}

@InProceedings{Shahzad2019,
  author    = {M. A. {Shahzad} and R. {Noor} and S. {Ahmad} and A. {Mian} and F. {Shafait}},
  booktitle = {Digital Image Computing: Techniques and Applications (DICTA)},
  date      = {2019-12-2},
  title     = {Feature Engineering Meets Deep Learning: A Case Study on Table Detection in Documents},
  pages     = {1-6},
  year      = {2019},
}

@Article{Coueasnon2014,
  author = {Bertrand Coüasnon and Aurélie Lemaitre},
  date   = {2014-11-25},
  title  = {Recognition of Tables and Forms},
}

@Article{Kasar2014,
  author       = {Thotreingam Kasar and Philippine Barlas and Adam Sébastien and Clément Chatelain and Thierry Paquet},
  date         = {2014-01-22},
  journaltitle = {12th International Conference on Document Analysis and Recognition (ICDAR)},
  title        = {Learning to Detect Tables in Scanned Document Images using Line Information},
  abstract     = {This paper presents a method to detect table
regions in document images by identifying the column and row line-separators and their properties. The method employs a run-length approach to identify the horizontal and vertical lines present in the input image. From each group of intersecting
horizontal and vertical lines, a set of 26 low-level features are extracted and an SVM classifier is used to test if it belongs to a table or not. The performance of the method is evaluated on a
heterogeneous corpus of French, English and Arabic documents that contain various types of table structures and compared with that of the Tesseract OCR system.},
}

@Article{Embley2006,
  author       = {David W. Embley and Matthew Hurst and Daniel Lopresti and George Nagy},
  date         = {2006-06-09},
  journaltitle = {International Journal of Document Analysis and Recognition (IJDAR)},
  title        = {Table-processing paradigms: a research survey},
  doi          = {https://doi.org/10.1007/s10032-006-0017-x},
  number       = {2-3},
  pages        = {66--86},
  volume       = {8},
  journal      = {International Journal of Document Analysis and Recognition ({IJDAR})},
  month        = {may},
  publisher    = {Springer Science and Business Media {LLC}},
  year         = {2006},
}

@InProceedings{Watanabe1991,
  author    = {T. Watanabe and H. Naruse and Q. Luo and N. Sugie},
  booktitle = {Intl. Conf. Document Analysis andRecognition},
  date      = {1991},
  title     = {Structure analysis of table-form documents on the basis of the recognition of vertical and horizontal line segments},
  pages     = {638-646},
}

@InProceedings{Laurentini1992,
  author    = {A. Laurentini and P. Viada},
  booktitle = {Proceedings., 11th {IAPR} International Conference on Pattern Recognition. Vol.{II}. Conference B: Pattern Recognition Methodology and Systems},
  date      = {1992-08-30},
  title     = {Identifying and understanding tabular material in compound documents},
  doi       = {10.1109/icpr.1992.201803},
  publisher = {{IEEE} Comput. Soc. Press},
}

@InProceedings{Pyreddy1997,
  author    = {Pyreddy, Pallavi and Croft, W. Bruce},
  booktitle = {Proceedings of the second {ACM} international conference on Digital libraries - {DL} {\textquotesingle}97},
  date      = {1997-07},
  title     = {TINTIN: A System for Retrieval in Text Tables},
  doi       = {10.1145/263690.263816},
  isbn      = {0897918681},
  location  = {New York, NY, USA},
  pages     = {193–200},
  publisher = {{ACM} Press},
  series    = {DL ’97},
  year      = {1997},
}

@InProceedings{Kieninger2001,
  author    = {T. Kieninger and A. Dengel},
  booktitle = {Proceedings of Sixth International Conference on Document Analysis and Recognition},
  date      = {2001-09-13},
  title     = {Applying the T-Recs table recognition system to the business letter domain},
  doi       = {10.1109/icdar.2001.953843},
  pages     = {518-522},
  publisher = {{IEEE} Comput. Soc},
}

@InProceedings{Wangt2001,
  author    = {Yalin Wangt and I. T. Phillipst and R. Haralick},
  booktitle = {Proceedings of Sixth International Conference on Document Analysis and Recognition},
  date      = {2001},
  title     = {Automatic table ground truth generation and a background-analysis-based table structure extraction method},
  doi       = {10.1109/icdar.2001.953845},
  pages     = {528-532},
  publisher = {{IEEE} Comput. Soc},
}

@InProceedings{Cesarini2002,
  author    = {F. Cesarini and S. Marinai and L. Sarti and G. Soda},
  booktitle = {Object recognition supported by user interaction for service robots},
  date      = {2002-08-11},
  title     = {Trainable table location in document images},
  doi       = {10.1109/icpr.2002.1047838},
  pages     = {236-240},
  publisher = {{IEEE} Comput. Soc},
  volume    = {3},
}

@Article{Mandal2006,
  author       = {S. Mandal and S. P. Chowdhury and A. K. Das and Bhabatosh Chanda},
  date         = {2006-03-24},
  journaltitle = {International Journal of Document Analysis and Recognition (IJDAR)},
  title        = {A simple and effective table detection system from document images},
  doi          = {10.1007/s10032-005-0006-5},
  number       = {2-3},
  pages        = {172-182},
  volume       = {8},
  abstract     = {The requirement of detection and identification of tables from document images is crucial to any document image analysis and digital library system. In this paper we report a very simple but extremely powerful approach to detect tables present in document pages. The algorithm relies on the observation that the tables have distinct columns which implies that gaps between the fields are substantially larger than the gaps between the words in text lines. This deceptively simple observation has led to the design of a simple but powerful table detection system with low computation cost. Moreover, mathematical foundation of the approach is also established including formation of a regular expression for ease of implementation.},
  journal      = {International Journal of Document Analysis and Recognition ({IJDAR})},
  month        = {mar},
  publisher    = {Springer Science and Business Media {LLC}},
  year         = {2006},
}

@InProceedings{Silva2009,
  author    = {Ana Costa Silva},
  booktitle = {10th International Conference on Document Analysis and Recognition},
  date      = {2009-07-26},
  title     = {Learning Rich Hidden Markov Models in Document Analysis: Table Location},
  doi       = {10.1109/icdar.2009.185},
  pages     = {843-847},
  publisher = {{IEEE}},
  year      = {2009},
}

@InProceedings{Kasar2013,
  author    = {T. Kasar and P. Barlas and S. Adam and C. Chatelain and T. Paquet},
  booktitle = {12th International Conference on Document Analysis and Recognition},
  date      = {2013-08-25},
  title     = {Learning to Detect Tables in Scanned Document Images Using Line Information},
  doi       = {10.1109/icdar.2013.240},
  pages     = {1185-1189},
  publisher = {{IEEE}},
  month     = {aug},
  year      = {2013},
}

@Article{Fan2015,
  author = {Miao Fan and Doo Soon Kim},
  date   = {2015},
  title  = {Detecting Table Region in PDF Documents Using Distant Supervision},
}

@Article{Tran2015,
  author       = {Tran, Dieu and Aly, Teppi and Oh, Aran and Kim, Soo and Na, In},
  date         = {2015-12},
  journaltitle = {International Journal of Contents},
  title        = {Table Detection from Document Image using Vertical Arrangement of Text Blocks},
  number       = {4},
  pages        = {77-85},
  volume       = {11},
}

@InProceedings{Hao2016,
  author    = {Leipeng Hao and Liangcai Gao and Xiaohan Yi and Zhi Tang},
  booktitle = {12th {IAPR} Workshop on Document Analysis Systems ({DAS})},
  date      = {2016-04-11},
  title     = {A Table Detection Method for {PDF} Documents Based on Convolutional Neural Networks},
  doi       = {10.1109/das.2016.23},
  pages     = {287-292},
  publisher = {{IEEE}},
  month     = {apr},
  year      = {2016},
}

@InProceedings{Rashid2017,
  author    = {Sheikh Faisal Rashid and Abdullah Akmal and Muhammad Adnan and Ali Adnan Aslam and Andreas Dengel},
  booktitle = {14th {IAPR} International Conference on Document Analysis and Recognition ({ICDAR})},
  date      = {2017-11-09},
  title     = {Table Recognition in Heterogeneous Documents Using Machine Learning},
  doi       = {10.1109/icdar.2017.132},
  pages     = {777-782},
  publisher = {{IEEE}},
  volume    = {1},
  month     = {nov},
  year      = {2017},
}

@InProceedings{Gilani2017,
  author    = {Azka Gilani and Shah Rukh Qasim and Imran Malik and Faisal Shafait},
  booktitle = {14th {IAPR} International Conference on Document Analysis and Recognition ({ICDAR})},
  date      = {2017-11-09},
  title     = {Table Detection Using Deep Learning},
  doi       = {10.1109/icdar.2017.131},
  pages     = {771-776},
  publisher = {{IEEE}},
  volume    = {1},
  month     = {nov},
  year      = {2017},
}

@Article{Siddiqui2018,
  author       = {Shoaib Ahmed Siddiqui and Muhammad Imran Malik and Stefan Agne and Andreas Dengel and Sheraz Ahmed},
  date         = {2018-11-20},
  journaltitle = {IEEE Access},
  title        = {{DeCNT}: Deep Deformable {CNN} for Table Detection},
  doi          = {10.1109/access.2018.2880211},
  pages        = {74151-74161},
  volume       = {6},
  journal      = {{IEEE} Access},
  publisher    = {Institute of Electrical and Electronics Engineers ({IEEE})},
  year         = {2018},
}

@InProceedings{Green1996,
  author    = {E. Green and M. Krishnamoorthy},
  booktitle = {Proceedings of 3rd International Conference on Document Analysis and Recognition},
  date      = {1996-08-14},
  title     = {Model-based analysis of printed tables},
  doi       = {10.1109/icdar.1995.598979},
  isbn      = {0-8186-7128-9},
  pages     = {214-217},
  publisher = {{IEEE} Comput. Soc. Press},
  volume    = {1},
  abstract  = {We develop a strategy for extracting the underlying relational information from the images of printed tables. Visual clues that exist in the image are used for extracting first the physical, and then the logical structure of the table. Since these visual clues generally have a logical meaning, there must be some association made between the graphical attributes extracted and their function of reflecting the logic expressed by the table; this knowledge is coordinated in a model. This approach, therefore, can be adapted to all tables which have graphical attributes discernible to the image analysis being used.},
}

@InProceedings{Oro2009,
  author    = {Ermelinda Oro and Massimo Ruffolo},
  booktitle = {10th International Conference on Document Analysis and Recognition},
  date      = {2009-07-26},
  title     = {{PDF}-{TREX}: An Approach for Recognizing and Extracting Tables from {PDF} Documents},
  doi       = {10.1109/icdar.2009.12},
  pages     = {906-910},
  publisher = {{IEEE}},
  year      = {2009},
}

@InCollection{Zeiler2014,
  author    = {Matthew D. Zeiler and Rob Fergus},
  booktitle = {Computer Vision {\textendash} {ECCV} 2014},
  publisher = {Springer International Publishing},
  title     = {Visualizing and Understanding Convolutional Networks},
  year      = {2014},
  pages     = {818--833},
  abstract  = {Large Convolutional Network models have recently demonstrated impressive classification performance on the ImageNet benchmark Krizhevsky et al. [18]. However there is no clear understanding of why they perform so well, or how they might be improved. In this paper we explore both issues. We introduce a novel visualization technique that gives insight into the function of intermediate feature layers and the operation of the classifier. Used in a diagnostic role, these visualizations allow us to find model architectures that outperform Krizhevsky et al on the ImageNet classification benchmark. We also perform an ablation study to discover the performance contribution from different model layers. We show our ImageNet model generalizes well to other datasets: when the softmax classifier is retrained, it convincingly beats the current state-of-the-art results on Caltech-101 and Caltech-256 datasets.},
  date      = {2014},
  doi       = {10.1007/978-3-319-10590-1_53},
}

@Article{Simonyan2014,
  author       = {Simonyan, Karen and Zisserman, Andrew},
  title        = {Very Deep Convolutional Networks for Large-Scale Image Recognition},
  abstract     = {In this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting. Our main contribution is a thorough evaluation of networks of increasing depth using an architecture with very small (3x3) convolution filters, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16-19 weight layers. These findings were the basis of our ImageNet Challenge 2014 submission, where our team secured the first and the second places in the localisation and classification tracks respectively. We also show that our representations generalise well to other datasets, where they achieve state-of-the-art results. We have made our two best-performing ConvNet models publicly available to facilitate further research on the use of deep visual representations in computer vision.},
  date         = {2014-09},
  eprint       = {1409.1556},
  journaltitle = {arXiv},
}

@Article{Shelhamer2017,
  author       = {Evan Shelhamer and Jonathan Long and Trevor Darrell},
  journal      = {{IEEE} Transactions on Pattern Analysis and Machine Intelligence},
  title        = {Fully Convolutional Networks for Semantic Segmentation},
  year         = {2017},
  month        = {apr},
  number       = {4},
  pages        = {640--651},
  volume       = {39},
  date         = {2016-05-24},
  doi          = {10.1109/tpami.2016.2572683},
  issue        = {4},
  journaltitle = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  publisher    = {Institute of Electrical and Electronics Engineers ({IEEE})},
}

@InProceedings{Prasad2020,
  author    = {Devashish Prasad and Ayan Gadpal and Kshitij Kapadni and Manish Visave and Kavita Sultanpure},
  booktitle = {{IEEE}/{CVF} Conference on Computer Vision and Pattern Recognition Workshops ({CVPRW})},
  date      = {2020-06-14},
  title     = {{CascadeTabNet}: An approach for end to end table detection and structure recognition from image-based documents},
  doi       = {10.1109/cvprw50498.2020.00294},
  pages     = {2439-2447},
  publisher = {{IEEE}},
  abstract  = {An automatic table recognition method for interpretation of tabular data in document images majorly involves solving two problems of table detection and table structure recognition. The prior work involved solving both problems independently using two separate approaches. More recent works signify the use of deep learning-based solutions while also attempting to design an end to end solution. In this paper, we present an improved deep learning-based end to end approach for solving both problems of table detection and structure recognition using a single Convolution Neural Network (CNN) model. We propose CascadeTabNet: a Cascade mask Region-based CNN High-Resolution Network (Cascade mask R-CNN HRNet) based model that detects the regions of tables and recognizes the structural body cells from the detected tables at the same time. We evaluate our results on ICDAR 2013, ICDAR 2019 and Table-Bank public datasets. We achieved 3rd rank in ICDAR 2019 post-competition results for table detection while attaining the best accuracy results for the ICDAR 2013 and Table-Bank dataset. We also attain the highest accuracy results on the ICDAR 2019 table structure recognition dataset. Additionally, we demonstrate effective transfer learning and image augmentation techniques that enable CNNs to achieve very accurate table detection results. Code and dataset has been made available at: https://github.com/DevashishPrasad/CascadeTabNet},
  month     = {jun},
  year      = {2020},
}

@InProceedings{Gobel2013,
  author    = {Max Gobel and Tamir Hassan and Ermelinda Oro and Giorgio Orsi},
  booktitle = {12th International Conference on Document Analysis and Recognition},
  date      = {2013-10-15},
  title     = {{ICDAR} 2013 Table Competition},
  doi       = {10.1109/icdar.2013.292},
  pages     = {1449-1453},
  publisher = {{IEEE}},
  abstract  = {Table understanding is a well studied problem in document analysis, and many academic and commercial approaches have been developed to recognize tables in several document formats, including plain text, scanned page images and born-digital, object-based formats such as PDF. Despite the abundance of these techniques, an objective comparison of their performance is still missing. The Table Competition held in the context of ICDAR 2013 is our first attempt at objectively evaluating these techniques against each other in a standardized way, across several input formats. The competition independently addresses three problems: (i) table location, (ii) table structure recognition, and (iii) these two tasks combined. We received results from seven academic systems, which we have also compared against four commercial products. This paper presents our findings.},
  month     = {aug},
  year      = {2013},
}

@Book{VanRossum2009,
  author    = {Van Rossum, Guido and Drake, Fred L.},
  date      = {2009},
  title     = {Python 3 Reference Manual},
  isbn      = {1441412697},
  location  = {Scotts Valley, CA},
  publisher = {CreateSpace},
}

@Book{Oliphant2006,
  author    = {Oliphant, T.},
  date      = {2006},
  title     = {A guide to NumPy},
  publisher = {Trelgol Publishing USA},
  volume    = {1},
}

@InProceedings{McKinney2010,
  author    = {Wes McKinney},
  booktitle = {Proceedings of the 9th Python in Science Conference},
  date      = {2010},
  title     = {Data Structures for Statistical Computing in Python},
  doi       = {10.25080/majora-92bf1922-00a},
  pages     = {56-61},
  publisher = {{SciPy}},
  year      = {2010},
}

@WWW{GeeksforGeeks2020,
  author = {GeeksforGeeks},
  date   = {2020},
  title  = {Python | Pandas DataFrame},
  url    = {https://www.geeksforgeeks.org/python-pandas-dataframe/},
}

@WWW{Microsoft2020,
  author = {Microsoft},
  date   = {2020},
  title  = {De opmaak van een Excel-tabel wijzigen},
  url    = {https://support.microsoft.com/nl-nl/office/de-opmaak-van-een-excel-tabel-wijzigen-6789619f-c889-495c-99c2-2f971c0e2370},
}

@WWW{Tsjoen2020,
  author = {Apotheek Tsjoen},
  date   = {2020},
  title  = {Medicatieschema},
  url    = {https://apotheektsjoen.be/service/medicatieschema/},
}

@Article{Kay2007,
  author       = {Kay, Anthony},
  date         = {2007-07},
  journaltitle = {Linux J.},
  title        = {Tesseract: An Open-Source Optical Character Recognition Engine},
  doi          = {10.5555/1288165.1288167},
  issn         = {1075-3583},
  number       = {159},
  pages        = {2},
  volume       = {2007},
  abstract     = {If you really need OCR.},
}

@WWW{Lee2009,
  author   = {Matthias Lee},
  date     = {2009},
  title    = {Python-tesseract},
  url      = {https://pypi.org/project/pytesseract/},
  abstract = {Python-tesseract is a python wrapper for Google's Tesseract-OCR.},
}

@Book{Grinberg2018,
  author    = {Grinberg, Miguel},
  date      = {2018},
  title     = {Flask web development: developing web applications with python},
  publisher = {O'Reilly Media, Inc.},
}

@Article{Jain2014,
  author       = {Jain, Nilesh and Bhansali, Ashok and Mehta, Deepak},
  date         = {2014},
  journaltitle = {Journal of Global Research in Computer Science},
  title        = {AngularJS: A modern MVC framework in JavaScript},
  number       = {12},
  pages        = {17--23},
  volume       = {5},
}

@Book{Fedosejev2016,
  author = {Artemij Fedosejev},
  date   = {2016-01},
  title  = {React.js Essentials},
  isbn   = {978-1-78355-162-0},
  pages  = {194},
}

@WWW{Financial2020,
  author = {Ant Financial},
  date   = {2020},
  title  = {Ant Design},
  url    = {https://ant.design/},
}

@Comment{jabref-meta: databaseType:biblatex;}
